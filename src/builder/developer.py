from openai import OpenAI
import yaml
client = OpenAI()

def generate_code(defintion_file : str):
  file = defintion_file
  with open(file, 'r') as file:
      project = yaml.safe_load(file)

  response = client.chat.completions.create(
    model="gpt-4-0125-preview",
    messages=[
      {
        "role": "system",
        "content": "You are a helpful, highly skilled and motivated senior developer at a company called Ariad. Your job as as a developer is to take project definitions and create code to implement the defined project.\nHere is the documentation for the definition you will receive:\n\n# Ariad - Declarative Language\n\nAn Ariad project begins with the creation of a YAML document where you declare your project's structure and components. Writing YAML can be intricate, but with ChatGPT, you can easily articulate your project requirements and kickstart the YAML creation process.\n\nStarting an Ariad project involves understanding its various components and how they interact within its unique architecture.\n\n## Architecture\n\nThe architecture of Ariad is designed to be modular and flexible, enabling the independent development and integration of various components. Key concepts include Parts, GLUE, Components, and a Project Manager.\n\n### Parts\n\nEach 'Part' in Ariad represents a self-contained unit with specific inputs and outputs. Parts are designed to be developed independently, allowing for asynchronous and parallel development workflows.\n\n### GLUE\n\n'GLUE' acts as the linker within Ariad, connecting various Parts to form a cohesive Component. It defines how data flows from one Part to another and ensures that all Parts within a Component work in harmony.\n\n### Components\n\nA 'Component' in Ariad is a collection of Parts connected via GLUE. It takes an input, processes it through its constituent Parts, and then outputs the result. Components are the building blocks of an Ariad project, each serving a distinct function within the larger application.\n\n### Project Manager\n\nThe Project Manager in Ariad oversees the overall structure of the program. It defines the necessary Parts, the GLUE that combines these parts, and how they fit into the broader project context.\n\n### Templates\n\nComponents might follow certain templates, like an express backend server, providing a standardized approach to common functionalities within the project.\n\n### Views\n\nAriad offers two primary views - the admin view and the working view. The admin view is for designing Components and the overall project, defining Parts and their interactions. The working view, akin to a leet-code-like interface, allows developers to select or assign Parts to code.\n\n## Project Definition in YAML\n\nAriad projects are entirely declared in YAML. This includes defining the project's structure, Components, and their interactions. Here's an example of how a project can be declared:\n\n1. The YAML file starts with the keyword `Project:` followed by the project details.\n2. The project details include:\n   - `Name:`: The name of the project.\n   - `Description:`: A brief description of the project.\n   - A list of components, each starting with a unique identifier like `C_Backend:` or `C_Frontend:`.\n3. Each component has:\n   - `Name:`: The name of the component.\n   - `Description:`: A brief description of the component.\n   - A list of parts, each starting with a unique identifier like `P_AddProduct:` or `P_GetProduct:`.\n4. Each part has:\n   - `Name:`: The name of the part.\n   - `Description:`: A brief description of the part.\n   - `Input:`: The input details, which include:\n     - `Name:`: The name of the input.\n     - `Type:`: The type of the input.\n     - `Description:`: A brief description of the input.\n     - `Properties:`: The properties of the input, each with a `Name:`, `Type:`, and `Description:`.\n     - `Value:`: The value of the input.\n   - `Output:`: The output details, similar to the input details.\n5. Each component also has a `GLUE:` section that describes the flow of data between the parts. It includes:\n   - `Graph:`: The flow of data, represented as `Part1 -> Part2`.\n   - `Description:`: A brief description of the data flow.\n\n---\nIt is your job to write professional and fully complete code that reflects the project definition in its fullest"
      },
      {
        "role": "user",
        "content": "```yaml\nProject:\n  Name: \"MUN Conference Whisper Command Recognition\"\n  Description: >\n    An easy way to keep track of peopleâ€™s speeches, recognition by the chairs, motions proposed, and more. \n    A tool to make moderating easier and allow them to make the most out of their and delegates' times.\n\n  C_AudioProcessing:\n    Name: Audio Processing\n    Description: >\n      Handles the processing of audio input, including speech recognition and command classification.\n    P_RecordSnippet:\n      Name: Record Snippet\n      Description: Records a snippet of audio\n      Input:\n        Name: duration\n        Type: Number\n        Description: The duration of the audio snippet\n        Value: 5\n      Output:\n        Name: audio\n        Type: String\n        Description: The audio file\n        Value: \"audio.wav\"\n    P_Recognize:\n      Name: Recognize\n      Description: Recognizes the speech and returns the recognized text\n      Input:\n        Name: audio\n        Type: String\n        Description: The audio file to be recognized\n        Value: \"audio.wav\"\n      Output:\n        Name: recognizedText\n        Type: String\n        Description: The recognized text\n        Value: \"Hello, my name is John Doe\"\n    P_Classify:\n      Name: Classify\n      Description: Classifies the recognized text into a command\n      Input:\n        Name: recognizedText\n        Type: String\n        Description: The recognized text\n        Value: \"... is the reason why. The delegate of the United States has the floor.\"\n      Output:\n        Name: command\n        Type: String\n        Description: The classified command\n        Value: \"FLOOR.USA\"\n\n    GLUE:\n      Graph: P_RecordSnippet -> P_Recognize -> P_Classify\n      Description: Connects the recognition process to the command classification\n```"
      },
      {
        "role": "assistant",
        "content": "audio_processing.py\n---\n```python\nimport sounddevice as sd\nimport random\nimport numpy as np\nimport scipy.io.wavfile as wav\nimport os\nimport whisper\nmodel = whisper.load_model(\"base\")\n\ndef record_snippet(duration : int) -> str:\n    # Set the sample rate and the number of channels for the audio capture\n    id = [str(random.randint(1,9)) for i in range(5)]\n    id = \"_\".join(id)\n    filename = f\"{id}transcript.wav\"\n    sample_rate = 16000\n    channels = 1\n\n    # Create a buffer to hold the audio data\n    buffer = []\n\n    # Create a callback function to capture audio data\n    def callback(indata, frames, time, status):\n        buffer.append(indata.copy())\n\n    # Create a stream to capture audio\n    stream = sd.InputStream(callback=callback, channels=channels, samplerate=sample_rate)\n\n    print(\"Recording...\")\n    # Start the audio stream and record for the specified duration\n    with stream:\n        sd.sleep(duration * 1000)\n\n    print(\"Finished recording.\")\n\n    # Convert the buffer to a NumPy array\n    audio_data = np.concatenate(buffer, axis=0)\n\n    # Save the audio data to a WAV file\n    wav.write(filename, sample_rate, audio_data)\n\n    # Return the file path\n    return os.path.abspath(filename)\n\ndef transcribe(audio_file: str) -> str: # ?\n    result = model.transcribe(audio_file)\n    return result[\"text\"]\n\n\ndef classify(transcription: str) -> str or None:\n    keyword = 'floor is yours'\n    if keyword in transcription.lower():\n        return 'floor.given'\n    return None\n\n\ndef AudioProcessingComponentPipeline(time : int) -> str or None:\n    io_pipeline = [\n        record_snippet,\n        transcribe,\n        classify\n    ]\n\n    nxt = time\n    while io_pipeline:\n        nxt = io_pipeline.pop(0)(nxt)\n    return nxt\n```\n\nmain.py\n---\n```python\nfrom audio_processing import AudioProcessingComponentPipeline\nimport warnings\nRECORDING_TIME = 5\n\n\ndef main():\n    warnings.filterwarnings(\"ignore\")\n    print(\"Starting audio processing component...\")\n    print(\"Press Ctrl+C to stop the program.\")\n    action = None\n    while True:\n        try:\n            action = AudioProcessingComponentPipeline(RECORDING_TIME)\n        except KeyboardInterrupt:\n            print(\"Stopping audio processing component...\")\n            break\n        if action is not None:\n            print(f\"Action: {action}\")\n        else:\n            print(\"No action detected.\")\n\n\nif __name__ == \"__main__\":\n    main()\n```"
      },
      {
        "role": "user",
        "content": "```yaml\nProject:\n  Name: Todo App\n  Description: A simple Todo application\n  C_TodoManager:\n    Name: Todo Manager\n    Description: Handles the todo list\n    P_AddTodo:\n      Name: Add Todo\n      Description: Adds a todo to the list\n      Input:\n        Name: todoItem\n        Type: String\n        Description: The todo item to be added\n        Value: \"Buy groceries\"\n      Output:\n        Name: todoList\n        Type: Array\n        Description: The updated todo list\n        Value: [\"Buy groceries\"]\n    P_RemoveTodo:\n      Name: Remove Todo\n      Description: Removes a todo from the list\n      Input:\n        Name: todoItem\n        Type: String\n        Description: The todo item to be removed\n        Value: \"Buy groceries\"\n      Output:\n        Name: todoList\n        Type: Array\n        Description: The updated todo list\n        Value: []\n    GLUE:\n      Graph: P_AddTodo -> P_RemoveTodo\n      Description: Connects the add and remove todo processes\n  C_UserInterface:\n    Name: User Interface\n    Description: Displays the todo list\n    P_DisplayTodos:\n      Name: Display Todos\n      Description: Displays the todo list\n      Input:\n        Name: todoList\n        Type: Array\n        Description: The todo list to be displayed\n        Value: []\n      Output:\n        Name: displayMessage\n        Type: String\n        Description: Message displaying the todo list\n        Value: \"You have no todos left!\"\n    GLUE:\n      Graph: P_DisplayTodos\n      Description: Connects the display todos process\n  C_CLI:\n    Name: Command Line Interface\n    Description: Handles user input and output on the command line\n    P_CLI_Loop:\n      Name: CLI Loop\n      Description: Continuously takes user input and calls the appropriate parts\n      Input:\n        Name: userInput\n        Type: String\n        Description: The user input from the command line\n        Value: \"add Buy groceries\"\n      Output:\n        Name: outputMessage\n        Type: String\n        Description: The output message to be displayed on the command line\n        Value: \"Todo added: Buy groceries\"\n    GLUE:\n      Graph: P_CLI_Loop\n      Description: Connects the CLI loop process\n```"
      },
      {
        "role": "assistant",
        "content": "main.py\n---\n```python\n# Global todo list\ntodoList = []\n\n\ndef add_todo(todoItem):\n    \"\"\"Adds a todo item to the list.\"\"\"\n    todoList.append(todoItem)\n    return todoList\n\n\ndef remove_todo(todoItem):\n    \"\"\"Removes a todo item from the list.\"\"\"\n    if todoItem in todoList:\n        todoList.remove(todoItem)\n    return todoList\n\n\ndef display_todos(todoList):\n    \"\"\"Displays the todo list.\"\"\"\n    if not todoList:\n        return \"You have no todos left!\"\n    return \"Your Todos: \" + \", \".join(todoList)\n\ndef cli_loop():\n    global todoList\n    while True:\n        userInput = input(\"Enter command: \")\n        if userInput.startswith(\"add \"):\n            todoItem = userInput[4:]\n            updatedList = add_todo(todoItem)\n            print(f\"Todo added: {todoItem}\")\n        elif userInput.startswith(\"remove \"):\n            todoItem = userInput[7:]\n            updatedList = remove_todo(todoItem)\n            print(f\"Todo removed: {todoItem}\")\n        elif userInput == \"display\":\n            displayMessage = display_todos(todoList)\n            print(displayMessage)\n        elif userInput == \"exit\":\n            break\n        else:\n            print(\"Unknown command. Please use 'add', 'remove', 'display', or 'exit'.\")\n\n# Entry point for the application\ncli_loop()\n```"
      },
        {
          "role": "user",
          "content": f"```yaml\n{project}\n```"
        }
    ],
    temperature=1,
    max_tokens=2500,
    top_p=1,
    frequency_penalty=0,
    presence_penalty=0
  )

  print(response)
  code = response.choices[0].message.content
  print(code)
  file_name = defintion_file.split('.')[0]
  file_name += ".ariad.code.md"
  with open(file_name, 'w') as f:
      f.write(code)

